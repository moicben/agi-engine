{
  "content": "{\n  \"stage\": \"Plan\",\n  \"iteration\": \"1\",\n  \"tasks\": [\n    {\n      \"id\": \"t1\",\n      \"name\": \"Validate and clarify user question\",\n      \"objective\": \"Determine whether the user's QA intent is unambiguous and complete; if not, generate a concise clarifying question to obtain missing context.\",\n      \"inputs\": {\n        \"user_query\": \"<raw user message text>\",\n        \"conversation_history\": \"<recent messages up to 3 turns, optional>\",\n        \"minimum_required_fields\": [\"topic\", \"desired depth\", \"any constraints (format/length/timeframe)\"]\n      },\n      \"outputs\": {\n        \"clarity_flag\": \"<boolean: true if question is clear>\",\n        \"clarifying_question\": \"<string or null>\",\n        \"parsed_intent\": {\n          \"topic\": \"<string or null>\",\n          \"depth\": \"<'brief'|'detailed'|'stepwise'|'explain-like-5'|null>\",\n          \"constraints\": \"<object or null>\"\n        }\n      },\n      \"actions\": [\n        \"Normalize user_query by trimming whitespace and lowercasing for checks only (do not alter original).\",\n        \"Extract explicit topic tokens using keyword matching and named-entity heuristics.\",\n        \"Extract explicit depth/format constraints (keywords: 'brief', 'detailed', 'steps', 'summary', 'code', 'citations', 'length', 'timeframe').\",\n        \"Apply ambiguity rules: mark ambiguous if topic is empty OR topic confidence < 0.7 OR multiple conflicting depth constraints found OR query length < 6 characters.\",\n        \"If ambiguous, construct a single clarifying question that asks only for the missing field(s) using up to 20 words; set clarity_flag=false and include clarifying_question.\",\n        \"If not ambiguous, populate parsed_intent fields and set clarity_flag=true and clarifying_question=null.\"\n      ],\n      \"dependencies\": [],\n      \"acceptance\": [\n        \"clarity_flag is a boolean\",\n        \"If clarity_flag is false then clarifying_question is a non-empty string <= 20 words\",\n        \"If clarity_flag is true then parsed_intent.topic is non-null and depth is one of the allowed values or null\"\n      ],\n      \"risks\": [\n        \"Heuristics may misclassify a clear but unusually phrased question as ambiguous\",\n        \"Overly strict ambiguity rules may prompt unnecessary clarifying questions\"\n      ],\n      \"mitigations\": [\n        \"When close to threshold (confidence 0.6-0.7), prefer treating as clear and proceed but mark lower confidence in outputs\",\n        \"If clarifying_question is asked, include explicit examples to minimize back-and-forth\"\n      ]\n    },\n    {\n      \"id\": \"t2\",\n      \"name\": \"Generate verified QA response\",\n      \"objective\": \"Produce a concise, accurate answer to the parsed user question, include stepwise reasoning, a confidence score, and source citations where applicable.\",\n      \"inputs\": {\n        \"clarity_flag\": \"<output.clarity_flag from t1>\",\n        \"clarifying_question_response\": \"<user reply if t1 produced a question, else null>\",\n        \"parsed_intent\": \"<output.parsed_intent from t1>\",\n        \"knowledge_cutoff\": \"2024-06\",\n        \"response_limits\": {\n          \"max_tokens\": 800,\n          \"preferred_length\": \"brief if depth='brief', otherwise detailed\"\n        }\n      },\n      \"outputs\": {\n        \"final_answer\": \"<string>\",\n        \"reasoning_summary\": \"<string: 1-3 concise steps explaining how the answer was derived>\",\n        \"confidence_score\": \"<number between 0 and 1>\",\n        \"citations\": [\"<strings or empty array>\"],\n        \"follow_up\": \"<optional clarifying or next-step suggestion>\"\n      },\n      \"actions\": [\n        \"If clarity_flag is false, do not generate final answer; instead return empty final_answer and instruct system to prompt user with clar"
}